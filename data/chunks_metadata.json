[
  {
    "id": "3f8016ab-8ea4-4fd3-98ec-4027f30185c5",
    "doc_id": "doc_1_3e92e9de",
    "doc_name": "cours deep learning.pdf",
    "chunk_index_in_doc": 0,
    "text": "Introduction au Deep Learning (notes de cours) Romain Tavenard 28 novembre 2023TABLE DES MATIÃˆRES 1 Introduction 3 1.1 Un premier modÃ¨le : le perceptron . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 Optimisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.3 RÃ©capitulatif . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2 Perceptrons multicouches 9 2.1 Empiler des couches pour une meilleure expressivitÃ© . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.2 DÃ©cider de lâ€™architecture dâ€™un MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.3 Fonctions dâ€™activation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.4 DÃ©clarer un MLP en keras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 3 Fonctions de coÃ»t 17 3.1 Erreur quadratique moyenne . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 3.2 Perte logistique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 4 Optimisation 19 4.1 Descente de gradient stochastique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 4.2 Une note sur Adam . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 4.3 La malÃ©diction de la profondeur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 4.4 Coder tout cela en keras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 4.5 PrÃ©traitement des donnÃ©es . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 5 RÃ©gularisation 27 5.1 Early stopping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 5.2 PÃ©nalisation de la perte . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 5.3 DropOut . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 6 RÃ©seaux neuronaux convolutifs 33 6.1 RÃ©seaux de neurones convolutifs pour les sÃ©ries temporelles . . . . . . . . . . . . . . . . . . . . . . . 33 6.2 RÃ©seaux de neurones convolutifs pour les images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 7 RÃ©seaux neuronaux rÃ©currents 41 7.1 RÃ©seaux rÃ©currents standard . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 7.2 Long Short Term Memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 7.3 Gated Recurrent Unit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 7.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 iBibliographie 47 iiIntroduction au Deep Learning (notes de cours) par Romain Tavenard Ce document sert de notes de cours pour un cours dispensÃ© Ã  lâ€™UniversitÃ© de Rennes 2 (France) et Ã  lâ€™EDHEC Lille (France). Le cours traite des bases des rÃ©seaux de neurones pour la classification et la rÃ©gression sur des donnÃ©es tabulaires (y compris les algorithmes dâ€™optimisation pour les perceptrons multicouches), les rÃ©seaux de neurones convolutifs pour la classification dâ€™images (y compris les notions dâ€™apprentissage par transfert) et la classification / prÃ©vision de sÃ©quences. Les sÃ©ances de travaux pratiques de ce cours utiliseront keras , tout comme ces notes de cours. NB : ces notes ont Ã©tÃ© traduites vers le franÃ§ais de maniÃ¨re semi-automatique, nâ€™hÃ©sitez pas Ã  vous rÃ©fÃ©rer Ã  la version anglaise en cas de doute. TABLE DES MATIÃˆRES 1Introduction au Deep Learning (notes de cours) 2 TABLE DES MATIÃˆRESCHAPITRE 1 INTRODUCTION Dans ce chapitre dâ€™introduction, nous allons prÃ©senter un premier rÃ©seau neuronal appelÃ© le Perceptron. Ce modÃ¨le est un rÃ©seau neuronal constituÃ© dâ€™un seul neurone, et nous lâ€™utiliserons ici pour introduire des concepts-clÃ©s que nous dÃ©taillerons plus tard dans le cours. 1.1Un premier modÃ¨le : le perceptron Dans la terminologie des rÃ©seaux de neurones, un neurone est une fonction paramÃ©trÃ©e qui prend un vecteur xen entrÃ©e et sort une valeur unique ğ‘comme suit : ğ‘ = ğœ‘( wx + ğ‘ âŸ ğ‘œ), oÃ¹ les paramÃ¨tres du neurone sont ses poids stockÃ©s dans w. et un terme de biais ğ‘, et ğœ‘est une fonction dâ€™activation qui est choisie a priori (nous y reviendrons plus en dÃ©tail plus tard dans le cours) : ğ‘œ ğ‘ğ‘¥0 ğ‘¥1 ğ‘¥2 ğ‘¥3 +1ğ‘¤ 0 ğ‘¤ 1 ğ‘¤2 ğ‘¤3 ğ‘ğœ‘ Un modÃ¨le constituÃ© dâ€™un seul neurone est appelÃ© perceptron. 3Introduction au Deep Learning (notes de cours) 1.2Optimisation Les modÃ¨les prÃ©sentÃ©s dans ce document ont pour but de rÃ©soudre des problÃ¨mes de prÃ©diction dans lesquels lâ€™objectif est de trouver des valeurs de paramÃ¨tres Â« suffisamment bonnes Â» pour le modÃ¨le en jeu compte tenu de donnÃ©es observÃ©es. Le problÃ¨me de la recherche de telles valeurs de paramÃ¨tres est appelÃ© optimisation. Lâ€™apprentissage profond (ou deep learning ) fait un usage intensif dâ€™une famille spÃ©cifique de stratÃ©gies dâ€™optimisation appelÃ©e descente gradiente . 1.2.1Descente de gradient Pour se faire une idÃ©e de la descente de gradient, supposons que lâ€™on nous donne le jeu de donnÃ©es suivant sur les prix de lâ€™immobilier : import pandas aspd boston =pd.read_csv( \"../data/boston.csv \")[[\"RM\",\"PRICE \"]] boston RM PRICE 0 6.575 24.0 1 6.421 21.6 2 7.185 34.7 3 6.998 33.4 4 7.147 36.2 .. ... ... 501 6.593 22.4 502 6.120 20.6 503 6.976 23.9 504 6.794 22.0 505 6.030 11.9 [506 rows x 2 columns] Dans notre cas, nous essaierons (pour commencer) de prÃ©dire la valeur cible \"PRICE\" de ce jeu de donnÃ©es, qui est la valeur mÃ©diane des maisons occupÃ©es par leur propriÃ©taire en milliers de dollars en fonction du nombre moyen de piÃ¨ces par logement \"RM\" : sns.scatterplot(data =boston, x =\"RM\", y=\"PRICE \"); 4 Chapitre 1. IntroductionIntroduction au Deep Learning (notes de cours) Une courte note sur ce modÃ¨le Dans la terminologie du Perceptron, ce modÃ¨le : â€”nâ€™a pas de fonction dâ€™activation ( i.e. ğœ‘est la fonction dâ€™identitÃ©) â€”nâ€™a pas de biais ( i.e. ğ‘est fixÃ© Ã  0, il nâ€™est pas appris) Supposons que nous ayons une approche naÃ¯ve dans laquelle notre modÃ¨le de prÃ©diction est linÃ©aire sans biais, câ€™est-Ã -dire que pour une entrÃ©e donnÃ©e ğ‘¥ğ‘–la sortie prÃ©dite est calculÃ©e comme suit : Ì‚ ğ‘¦ğ‘–= ğ‘¤ğ‘¥ğ‘– oÃ¹ ğ‘¤est le seul paramÃ¨tre de notre modÃ¨le. Supposons en outre que la quantitÃ© que nous cherchons Ã  minimiser (notre objectif, Ã©galement appelÃ© fonction de perte) est : â„’(ğ‘¤) = âˆ‘ ğ‘–( Ì‚ ğ‘¦ğ‘–âˆ’ ğ‘¦ğ‘–)2 oÃ¹ ğ‘¦ğ‘–est la valeur cible associÃ©e au ğ‘–-Ã¨me Ã©chantillon de jeu de donnÃ©es. Examinons cette quantitÃ© en fonction de ğ‘¤: import numpy asnp def loss (w, x, y): w=np.array(w) return np.sum( (w[:, None ]*x.to_numpy()[ None , :] -y.to_numpy()[ None , :]) **2, axis =1 ) w=np.linspace( -2,10, num =100) x=boston[ \"RM\"] y=boston[ \"PRICE \"] plt.plot(w, loss(w, x, y), \"r-\"); 1.2. Optimisation 5Introduction au Deep Learning (notes de cours) Ici, il semble quâ€™une valeur de ğ‘¤autour de 4 devrait Ãªtre un bon choix. Cette mÃ©thode (gÃ©nÃ©rer de nombreuses valeurs pour le paramÃ¨tre et calculer la perte pour chaque valeur) ne peut pas sâ€™adapter aux modÃ¨les qui ont beaucoup de paramÃ¨tres, donc nous allons donc essayer autre chose. Supposons que nous ayons accÃ¨s, Ã  chaque fois que nous choisissons une valeur candidate pour ğ‘¤, Ã  la fois Ã  la perte â„’et aux informations sur la faÃ§on dont â„’varie, localement. Nous pourrions, dans ce cas, calculer une nouvelle valeur candidate pour ğ‘¤en nous dÃ©plaÃ§ant Ã  partir de la valeur candidate prÃ©cÃ©dente dans la direction de la descente la plus raide. Câ€™est lâ€™idÃ©e de base de lâ€™algorithme de descente du gradient qui, Ã  partir dâ€™un candidat initial ğ‘¤0, calcule itÃ©rativement de nouveaux candidats comme : ğ‘¤ğ‘¡+1 = ğ‘¤ğ‘¡âˆ’ ğœŒğœ•â„’ ğœ•ğ‘¤âˆ£ ğ‘¤=ğ‘¤ğ‘¡ oÃ¹ ğœŒest un hyper-paramÃ¨tre (appelÃ© taux dâ€™apprentissage) qui contrÃ´le la taille des pas Ã  effectuer, etğœ•â„’ ğœ•ğ‘¤âˆ£ğ‘¤=ğ‘¤ğ‘¡est le gradient de â„’par rapport Ã  ğ‘¤, Ã©valuÃ© en ğ‘¤ = ğ‘¤ğ‘¡. Comme vous pouvez le voir, la direction de la descente la plus raide est lâ€™opposÃ© de la direction indiquÃ©e par le gradient (et cela vaut aussi pour les paramÃ¨tres vectoriels). Ce processus est rÃ©pÃ©tÃ© jusquâ€™Ã  la convergence, comme lâ€™illustre la figure suivante : rho =1e-5 def grad_loss (w_t, x, y): return np.sum( 2*(w_t *x-y)*x ) ww=np.linspace( -2,10, num =100) plt.plot(ww, loss(ww, x, y), \"r-\", alpha =.5); w=[0.] for tinrange (10): w_update =w[t] -rho *grad_loss(w[t], x, y) w.append(w_update) plt.plot(w, loss(w, x, y), \"ko-\") plt.text(x =w[0]+.1, y=loss([w[ 0]], x, y), s =\"$w_{0}$\") plt.text(x =w[10]+.1, y=loss([w[ 10]], x, y), s =\"$w_{10} $\"); 6 Chapitre 1. IntroductionIntroduction au Deep Learning (notes de cours) Quâ€™obtiendrions-nous si nous utilisions un taux dâ€™apprentissage plus faible? rho =1e-6 ww=np.linspace( -2,10, num =100) plt.plot(ww, loss(ww, x, y), \"r-\", alpha =.5); w=[0.] for tinrange (10): w_update =w[t] -rho *grad_loss(w[t], x, y) w.append(w_update) plt.plot(w, loss(w, x, y), \"ko-\") plt.text(x =w[0]+.1, y=loss([w[ 0]], x, y), s =\"$w_{0}$\") plt.text(x =w[10]+.1, y=loss([w[ 10]], x, y), s =\"$w_{10} $\"); Cela prendrait certainement plus de temps pour converger. Mais attention, un taux dâ€™apprentissage plus Ã©levÃ© nâ€™est pas toujours une bonne idÃ©e : 1.2. Optimisation 7Introduction au Deep Learning (notes de cours) rho =5e-5 ww=np.linspace( -2,10, num =100) plt.plot(ww, loss(ww, x, y), \"r-\", alpha =.5); w=[0.] for tinrange (10): w_update =w[t] -rho *grad_loss(w[t], x, y) w.append(w_update) plt.plot(w, loss(w, x, y), \"ko-\") plt.text(x =w[0]-1., y=loss([w[ 0]], x, y), s =\"$w_{0}$\") plt.text(x =w[10]-1., y=loss([w[ 10]], x, y), s =\"$w_{10} $\"); Vous voyez comment nous divergeons lentement parce que nos pas sont trop grands? 1.3RÃ©capitulatif Dans cette section, nous avons introduit : â€”un modÃ¨le trÃ¨s simple, appelÃ© le Perceptron : ce sera une brique de base pour les modÃ¨les plus avancÃ©s que nous dÃ©taillerons plus tard dans le cours, tels que : â€”lePerceptron multi-couches â€”lesarchitectures convolutionnelles â€”lesarchitectures rÃ©currentes â€”le fait quâ€™une tÃ¢che sâ€™accompagne dâ€™une fonction de perte Ã  minimiser (ici, nous avons utilisÃ© lâ€™erreur quadratique moyenne pour notre tÃ¢che de rÃ©gression), qui sera discutÃ©e dans un chapitre dÃ©diÃ© ; â€”le concept de descente de gradient pour optimiser la perte choisie sur le paramÃ¨tre unique dâ€™un modÃ¨le, et ceci sera Ã©tendu dans notre chapitre sur lâ€™optimisation . 8 Chapitre 1. IntroductionCHAPITRE 2 PERCEPTRONS MULTICOUCHES Dans le chapitre prÃ©cÃ©dent, nous avons vu un modÃ¨le trÃ¨s simple appelÃ© le perceptron. Dans ce modÃ¨le, la sortie prÃ©dite Ì‚ ğ‘¦est calculÃ©e comme une combinaison linÃ©aire des caractÃ©ristiques dâ€™entrÃ©e plus un biais : Ì‚ ğ‘¦ =ğ‘‘ âˆ‘ ğ‘—=1ğ‘¥ğ‘—ğ‘¤ğ‘—+ ğ‘ En dâ€™autres termes, nous optimisions parmi la famille des modÃ¨les linÃ©aires, qui est une famille assez restreinte. 2.1Empiler des couches pour une meilleure expressivitÃ© Afin de couvrir un plus large Ã©ventail de modÃ¨les, on peut empiler des neurones organisÃ©s en couches pour former un modÃ¨le plus complexe, comme le modÃ¨le ci-dessous, qui est appelÃ© modÃ¨le Ã  une couche cachÃ©e, car une couche supplÃ©- mentaire de neurones est introduite entre les entrÃ©es et la sortie : Couche d'entrÃ©e xCouche cachÃ©e h(1)Couche de sortie Ì‚ y w(0)w(1) 9Introduction au Deep Learning (notes de cours) La question que lâ€™on peut se poser maintenant est de savoir si cette couche cachÃ©e supplÃ©mentaire permet effectivement de couvrir une plus grande famille de modÃ¨les. Câ€™est Ã  cela que sert le thÃ©orÃ¨me dâ€™approximation universelle ci-dessous. ThÃ©orÃ¨me dâ€™approximation universelle Le thÃ©orÃ¨me dâ€™approximation universelle stipule que toute fonction continue dÃ©finie sur un ensemble compact peut Ãªtre approchÃ©e dâ€™aussi prÃ¨s que lâ€™on veut par un rÃ©seau neuronal Ã  une couche cachÃ©e avec activation sigmoÃ¯de. En dâ€™autres termes, en utilisant une couche cachÃ©e pour mettre en correspondance les entrÃ©es et les sorties, on peut maintenant approximer nâ€™importe quelle fonction continue, ce qui est une propriÃ©tÃ© trÃ¨s intÃ©ressante. Notez cependant que le nombre de neurones cachÃ©s nÃ©cessaire pour obtenir une qualitÃ© dâ€™approximation donnÃ©e nâ€™est pas discutÃ© ici. De plus, il nâ€™est pas suffisant quâ€™une telle bonne approximation existe, une autre question importante est de savoir si les algorithmes dâ€™optimisation que nous utiliserons convergeront in fine vers cette solution ou non, ce qui nâ€™est pas garanti, comme discutÃ© plus en dÃ©tail dans le chapitre dÃ©diÃ© . En pratique, nous observons empiriquement que pour atteindre une qualitÃ© dâ€™approximation donnÃ©e, il est plus efficace (en termes de nombre de paramÃ¨tres requis) dâ€™empiler plusieurs couches cachÃ©es plutÃ´t que de sâ€™appuyer sur une seule : Couche d'entrÃ©e xPremiÃ¨re couche cachÃ©e h(1)Seconde couche cachÃ©e h(2)Couche de sortie Ì‚ y w(0)w(1)w(2) La reprÃ©sentation graphique ci-dessus correspond au modÃ¨le suivant : Ì‚ ğ‘¦= ğœ‘out (âˆ‘ ğ‘–ğ‘¤(2) ğ‘–â„(2) ğ‘– + ğ‘(2)) (2.1) âˆ€ğ‘–, â„(2) ğ‘– = ğœ‘ (âˆ‘ ğ‘—ğ‘¤(1) ğ‘–ğ‘—â„(1) ğ‘— + ğ‘(1) ğ‘–) (2.2) âˆ€ğ‘–, â„(1) ğ‘– = ğœ‘ (âˆ‘ ğ‘—ğ‘¤(0) ğ‘–ğ‘—ğ‘¥ğ‘—+ ğ‘(0) ğ‘–) (2.3) Pour Ãªtre prÃ©cis, les termes de biais ğ‘(ğ‘™) ğ‘–ne sont pas reprÃ©sentÃ©s dans la reprÃ©sentation graphique ci-dessus. De tels modÃ¨les avec une ou plusieurs couches cachÃ©es sont appelÃ©s Perceptrons multicouches (ouMulti-Layer Percep- trons, MLP). 10 Chapitre 2. Perceptrons multicouchesIntroduction au Deep Learning (notes de cours) 2.2DÃ©cider de lâ€™architecture dâ€™un MLP Lors de la conception dâ€™un modÃ¨le de perceptron multicouche destinÃ© Ã  Ãªtre utilisÃ© pour un problÃ¨me spÃ©cifique, certaines quantitÃ©s sont fixÃ©es par le problÃ¨me en question et dâ€™autres sont des hyper-paramÃ¨tres du modÃ¨le. Prenons lâ€™exemple du cÃ©lÃ¨bre jeu de donnÃ©es de classification dâ€™iris : import pandas aspd iris =pd.read_csv( \"../data/iris.csv \", index_col =0) iris sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) \\ 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 .. ... ... ... ... 145 6.7 3.0 5.2 2.3 146 6.3 2.5 5.0 1.9 147 6.5 3.0 5.2 2.0 148 6.2 3.4 5.4 2.3 149 5.9 3.0 5.1 1.8 target 0 0 1 0 2 0 3 0 4 0 .. ... 145 2 146 2 147 2 148 2 149 2 [150 rows x 5 columns] Lâ€™objectif ici est dâ€™apprendre Ã  dÃ©duire lâ€™attribut Â« cible Â» (3 classes diffÃ©rentes possibles) Ã  partir des informations conte- nues dans les 4 autres attributs. La structure de ce jeu de donnÃ©es dicte : â€”le nombre de neurones dans la couche dâ€™entrÃ©e, qui est Ã©gal au nombre dâ€™attributs descriptifs dans notre jeu de donnÃ©es (ici, 4), et â€”le nombre de neurones dans la couche de sortie, qui est ici Ã©gal Ã  3, puisque le modÃ¨le est censÃ© produire une probabilitÃ© par classe cible. De maniÃ¨re plus gÃ©nÃ©rale, pour la couche de sortie, on peut Ãªtre confrontÃ© Ã  plusieurs situations : â€”lorsquâ€™il sâ€™agit de rÃ©gression, le nombre de neurones de la couche de sortie est Ã©gal au nombre de caractÃ©ristiques Ã  prÃ©dire par le modÃ¨le, â€”quand il sâ€™agit de classification â€”Dans le cas dâ€™une classification binaire, le modÃ¨le aura un seul neurone de sortie qui indiquera la probabilitÃ© de la classe positive, 2.2. DÃ©cider de lâ€™architecture dâ€™un MLP 11Introduction au Deep Learning (notes de cours) â€”dans le cas dâ€™une classification multi-classes, le modÃ¨le aura autant de neurones de sortie que le nombre de classes du problÃ¨me. Une fois que ces nombres de neurones dâ€™entrÃ©e / sortie sont fixÃ©s, le nombre de neurones cachÃ©s ainsi que le nombre de neurones par couche cachÃ©e restent des hyper-paramÃ¨tres du modÃ¨le. 2.3Fonctions dâ€™activation Un autre hyper-paramÃ¨tre important des rÃ©seaux neuronaux est le choix de la fonction dâ€™activation ğœ‘. Il est important de noter que si nous utilisons la fonction identitÃ© comme fonction dâ€™activation, quelle que soit la profondeur de notre MLP, nous ne couvrirons plus que la famille des modÃ¨les linÃ©aires. En pratique, nous utiliserons donc des fonctions dâ€™activation qui ont un certain rÃ©gime linÃ©aire mais qui ne se comportent pas comme une fonction linÃ©aire sur toute la gamme des valeurs dâ€™entrÃ©e. Historiquement, les fonctions dâ€™activation suivantes ont Ã©tÃ© proposÃ©es : tanh (ğ‘¥) =2 1 + ğ‘’âˆ’2ğ‘¥âˆ’ 1 sigmoid (ğ‘¥) =1 1 + ğ‘’âˆ’ğ‘¥ ReLU (ğ‘¥) = {ğ‘¥siğ‘¥ > 0 0sinon En pratique, la fonction ReLU (et certaines de ses variantes) est la plus utilisÃ©e de nos jours, pour des raisons qui seront discutÃ©es plus en dÃ©tail dans notre chapitre consacrÃ© Ã  lâ€™optimisation . 2.3.1Le cas particulier de la couche de sortie Vous avez peut-Ãªtre remarquÃ© que dans la formulation du MLP fournie par lâ€™Ã©quation (1), la couche de sortie possÃ¨de sa propre fonction dâ€™activation, notÃ©e ğœ‘out. Cela sâ€™explique par le fait que le choix de la fonction dâ€™activation pour la couche de sortie dâ€™un rÃ©seau neuronal est spÃ©cifique au problÃ¨me Ã  rÃ©soudre. En effet, vous avez pu constater que les fonctions dâ€™activation abordÃ©es dans la section prÃ©cÃ©dente ne partagent pas la mÃªme plage de valeurs de sortie. Il est donc primordial de choisir une fonction dâ€™activation adÃ©quate pour la couche de sortie, de sorte que notre modÃ¨le produise des valeurs cohÃ©rentes avec les quantitÃ©s quâ€™il est censÃ© prÃ©dire. Si, par exemple, notre modÃ¨le est censÃ© Ãªtre utilisÃ© dans lâ€™ensemble de donnÃ©es sur les logements de Boston dont nous avons parlÃ© dans le chapitre prÃ©cÃ©dent , lâ€™objectif est de prÃ©dire les prix des logements, qui sont censÃ©s Ãªtre des quantitÃ©s non 12 Chapitre 2. Perceptrons multicouchesIntroduction au Deep Learning (notes de cours) nÃ©gatives. Il serait donc judicieux dâ€™utiliser ReLU (qui peut produire toute valeur positive) comme fonction dâ€™activation pour la couche de sortie dans ce cas. Comme indiquÃ© prÃ©cÃ©demment, dans le cas de la classification binaire, le modÃ¨le aura un seul neurone de sortie et ce neurone produira la probabilitÃ© associÃ©e Ã  la classe positive. Cette quantitÃ© devra se situer dans lâ€™intervalle [0, 1], et la fonction dâ€™activation sigmoÃ¯de est alors le choix par dÃ©faut dans ce cas. Enfin, lorsque la classification multi-classes est en jeu, nous avons un neurone par classe de sortie et chaque neurone est censÃ© fournir la probabilitÃ© pour une classe donnÃ©e. Dans ce contexte, les valeurs de sortie doivent Ãªtre comprises entre 0 et 1, et leur somme doit Ãªtre Ã©gale Ã  1. Ã€ cette fin, nous utilisons la fonction dâ€™activation softmax dÃ©finie comme suit : âˆ€ğ‘–,softmax (ğ‘œğ‘–) =ğ‘’ğ‘œğ‘– âˆ‘ğ‘—ğ‘’ğ‘œğ‘— oÃ¹, pour tous les ğ‘–, les ğ‘œğ‘–sont les valeurs des neurones de sortie avant application de la fonction dâ€™activation. 2.4DÃ©clarer un MLP en keras Pour dÃ©finir un modÃ¨le MLP dans keras , il suffit dâ€™empiler des couches. A titre dâ€™exemple, si lâ€™on veut coder un modÃ¨le composÃ© de : â€”une couche dâ€™entrÃ©e avec 10 neurones, â€”dâ€™une couche cachÃ©e de 20 neurones avec activation ReLU, â€”une couche de sortie composÃ©e de 3 neurones avec activation softmax, le code sera le suivant : import keras_core askeras from keras .layers import Dense, InputLayer from keras .models import Sequential model =Sequential([ InputLayer(input_shape =(10, )), Dense(units =20, activation =\"relu \"), Dense(units =3, activation =\"softmax \") ]) model .summary() Using TensorFlow backend Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 20) 220 dense_1 (Dense) (None, 3) 63 ================================================================= Total params: 283 (1.11 KB) Trainable params: 283 (1.11 KB) Non-trainable params: 0 (0.00 Byte) _________________________________________________________________ Notez que model.summary() fournit un aperÃ§u intÃ©ressant dâ€™un modÃ¨le dÃ©fini et de ses paramÃ¨tres. 2.4. DÃ©clarer un MLP en keras 13Introduction au Deep Learning (notes de cours) Exercice #1 En vous basant sur ce que nous avons vu dans ce chapitre, pouvez-vous expliquer le nombre de paramÃ¨tres retournÃ©s par model.summary() ci-dessus? Solution Notre couche dâ€™entrÃ©e est composÃ©e de 10 neurones, et notre premiÃ¨re couche est entiÃ¨rement connectÃ©e, donc chacun de ces neurones est connectÃ© Ã  un neurone de la couche cachÃ©e par un paramÃ¨tre, ce qui fait dÃ©jÃ  10 Ã— 20 = 200 paramÃ¨tres. De plus, chacun des neurones de la couche cachÃ©e possÃ¨de son propre paramÃ¨tre de biais, ce qui fait 20paramÃ¨tres supplÃ©mentaires. Nous avons donc 220 paramÃ¨tres, tels que sortis par model.summary() pour la couche \"dense (Dense)\" . De la mÃªme maniÃ¨re, pour la connexion des neurones de la couche cachÃ©e Ã  ceux de la couche de sortie, le nombre total de paramÃ¨tres est de 20 Ã— 3 = 60 pour les poids plus 3paramÃ¨tres supplÃ©mentaires pour les biais. Au total, nous avons 220 + 63 = 283 paramÃ¨tres dans ce modÃ¨le. Exercice #2 DÃ©clarez, en keras , un MLP avec une couche cachÃ©e composÃ©e de 100 neurones et une activation ReLU pour le jeu de donnÃ©es Iris prÃ©sentÃ© ci-dessus. Solution model =Sequential([ InputLayer(input_shape =(4, )), Dense(units =100, activation =\"relu \"), Dense(units =3, activation =\"softmax \") ]) Exercice #3 MÃªme question pour le jeu de donnÃ©es sur le logement Ã  Boston prÃ©sentÃ© ci-dessous (le but ici est de prÃ©dire lâ€™attribut PRICE en fonction des autres). Solution model =Sequential([ InputLayer(input_shape =(6, )), Dense(units =100, activation =\"relu \"), Dense(units =1, activation =\"relu \") ]) RM CRIM INDUS NOX AGE TAX PRICE 0 6.575 0.00632 2.31 0.538 65.2 296.0 24.0 (suite sur la page suivante) 14 Chapitre 2. Perceptrons multicouchesIntroduction au Deep Learning (notes de cours) (suite de la page prÃ©cÃ©dente) 1 6.421 0.02731 7.07 0.469 78.9 242.0 21.6 2 7.185 0.02729 7.07 0.469 61.1 242.0 34.7 3 6.998 0.03237 2.18 0.458 45.8 222.0 33.4 4 7.147 0.06905 2.18 0.458 54.2 222.0 36.2 .. ... ... ... ... ... ... ... 501 6.593 0.06263 11.93 0.573 69.1 273.0 22.4 502 6.120 0.04527 11.93 0.573 76.7 273.0 20.6 503 6.976 0.06076 11.93 0.573 91.0 273.0 23.9 504 6.794 0.10959 11.93 0.573 89.3 273.0 22.0 505 6.030 0.04741 11.93 0.573 80.8 273.0 11.9 [506 rows x 7 columns] 2.4. DÃ©clarer un MLP en keras 15Introduction au Deep Learning (notes de cours) 16 Chapitre 2. Perceptrons multicouchesCHAPITRE 3 FONCTIONS DE COÃ›T Nous avons maintenant prÃ©sentÃ© une premiÃ¨re famille de modÃ¨les, qui est la famille MLP. Afin dâ€™entraÃ®ner ces modÃ¨les (i.e.dâ€™ajuster leurs paramÃ¨tres pour quâ€™ils sâ€™adaptent aux donnÃ©es), nous devons dÃ©finir une fonction de coÃ»t (aussi appelÃ©e fonction de perte, ou loss function ) Ã  optimiser. Une fois cette fonction choisie, lâ€™optimisation consistera Ã  rÃ©gler les paramÃ¨tres du modÃ¨le de maniÃ¨re Ã  la minimiser. Dans cette section, nous prÃ©senterons deux fonctions de pertes standard, Ã  savoir lâ€™erreur quadratique moyenne (princi- palement utilisÃ©e pour la rÃ©gression) et la fonction de perte logistique (utilisÃ©e en classification). Dans ce qui suit, nous supposons connu un ensemble de donnÃ©es ğ’ŸcomposÃ© de ğ‘›Ã©chantillons annotÃ©s (ğ‘¥ğ‘–, ğ‘¦ğ‘–), et nous dÃ©signons la sortie du modÃ¨le : âˆ€ğ‘–, Ì‚ ğ‘¦ğ‘–= ğ‘šğœƒ(ğ‘¥ğ‘–) oÃ¹ ğ‘šğœƒest notre modÃ¨le et ğœƒest lâ€™ensemble de tous ses paramÃ¨tres (poids et biais). 3.1Erreur quadratique moyenne Lâ€™erreur quadratique moyenne (ou Mean Squared Error , MSE) est la fonction de perte la plus couramment utilisÃ©e dans les contextes de rÃ©gression. Elle est dÃ©finie comme suit â„’(ğ’Ÿ; ğ‘šğœƒ) =1 ğ‘›âˆ‘ ğ‘–â€– Ì‚ ğ‘¦ğ‘–âˆ’ ğ‘¦ğ‘–â€–2 =1 ğ‘›âˆ‘ ğ‘–â€–ğ‘šğœƒ(ğ‘¥ğ‘–) âˆ’ ğ‘¦ğ‘–â€–2 Sa forme quadratique tend Ã  pÃ©naliser fortement les erreurs importantes : 17Introduction au Deep Learning (notes de cours) 3.2Perte logistique La perte logistique est la fonction de perte la plus largement utilisÃ©e pour entraÃ®ner des rÃ©seaux neuronaux dans des contextes de classification. Elle est dÃ©finie comme suit â„’(ğ’Ÿ; ğ‘šğœƒ) =1 ğ‘›âˆ‘ ğ‘–âˆ’log ğ‘( Ì‚ ğ‘¦ğ‘–= ğ‘¦ğ‘–; ğ‘šğœƒ) oÃ¹ ğ‘( Ì‚ ğ‘¦ğ‘–= ğ‘¦ğ‘–; ğ‘šğœƒ)est la probabilitÃ© prÃ©dite par le modÃ¨le ğ‘šğœƒpour la classe correcte ğ‘¦ğ‘–. Sa formulation tend Ã  favoriser les cas oÃ¹ le modÃ¨le prÃ©dit la classe correcte avec une probabilitÃ© proche de 1, comme on peut sâ€™y attendre : 18 Chapitre 3. Fonctions de coÃ»tCHAPITRE 4 OPTIMISATION Dans ce chapitre, nous prÃ©senterons des variantes de la stratÃ©gie dâ€™optimisation de descente de gradient et montrerons comment elles peuvent Ãªtre utilisÃ©es pour optimiser les paramÃ¨tres des rÃ©seaux de neurones. CommenÃ§ons par lâ€™algorithme de base de la descente de gradient et ses limites. Algorithm 1 (Descente de Gradient) EntrÃ©e: Un jeu de donnÃ©es ğ’Ÿ = (ğ‘‹, ğ‘¦) 1.Initialiser les paramÃ¨tres ğœƒdu modÃ¨le 2.for ğ‘’ = 1..ğ¸ 1.for (ğ‘¥ğ‘–, ğ‘¦ğ‘–) âˆˆ ğ’Ÿ 1.Calculer la prÃ©diction Ì‚ ğ‘¦ğ‘–= ğ‘šğœƒ(ğ‘¥ğ‘–) 2.Calculer le gradient individuel âˆ‡ğœƒâ„’ğ‘– 2.Calculer le gradient total âˆ‡ğœƒâ„’ =1 ğ‘›âˆ‘ğ‘–âˆ‡ğœƒâ„’ğ‘– 3.Mettre Ã  jour les paramÃ¨tres ğœƒÃ  partir de âˆ‡ğœƒâ„’ La rÃ¨gle de mise Ã  jour typique pour les paramÃ¨tres ğœƒÃ  lâ€™itÃ©ration ğ‘¡est ğœƒ(ğ‘¡+1)â† ğœƒ(ğ‘¡)âˆ’ ğœŒâˆ‡ğœƒâ„’ oÃ¹ ğœŒest un hyper-paramÃ¨tre important de la mÃ©thode, appelÃ© le taux dâ€™apprentissage (ou learning rate ). La descente de gradient consiste Ã  jour itÃ©rativement ğœƒdans la direction de la plus forte diminution de la perte â„’. Comme on peut le voir dans lâ€™algorithme prÃ©cÃ©dent, lors dâ€™un descente de gradient, les paramÃ¨tres du modÃ¨le sont mis Ã  jour une fois par epoch, ce qui signifie quâ€™un passage complet sur lâ€™ensemble des donnÃ©es est nÃ©cessaire avant la mise Ã  jour. Lorsque lâ€™on traite de grands jeux de donnÃ©es, cela constitue une forte limitation, ce qui motive lâ€™utilisation de variantes stochastiques. 19Introduction au Deep Learning (notes de cours) 4.1Descente de gradient stochastique Lâ€™idÃ©e derriÃ¨re lâ€™algorithme de descente de gradient stochastique (ou Stochastic Gradient Descent , SGD) est dâ€™obtenir des estimations bon marchÃ© (au sens de la quantitÃ© de calculs nÃ©cessaires) pour la quantitÃ© âˆ‡ğœƒâ„’(ğ’Ÿ; ğ‘šğœƒ) =1 ğ‘›âˆ‘ (ğ‘¥ğ‘–,ğ‘¦ğ‘–)âˆˆğ’Ÿâˆ‡ğœƒâ„’(ğ‘¥ğ‘–, ğ‘¦ğ‘–; ğ‘šğœƒ) oÃ¹ ğ’Ÿest lâ€™ensemble dâ€™apprentissage. Pour ce faire, on tire des sous-ensembles de donnÃ©es, appelÃ©s minibatchs , et âˆ‡ğœƒâ„’(â„¬; ğ‘šğœƒ) =1 ğ‘âˆ‘ (ğ‘¥ğ‘–,ğ‘¦ğ‘–)âˆˆâ„¬âˆ‡ğœƒâ„’(ğ‘¥ğ‘–, ğ‘¦ğ‘–; ğ‘šğœƒ) est utilisÃ© comme estimateur de âˆ‡ğœƒâ„’(ğ’Ÿ; ğ‘šğœƒ). Il en rÃ©sulte lâ€™algorithme suivant dans lequel les mises Ã  jour des paramÃ¨tres se produisent aprÃ¨s chaque minibatch , câ€™est-Ã -dire plusieurs fois par epoch . Algorithm 2 (Descente de gradient stochastique) Input: A dataset ğ’Ÿ = (ğ‘‹, ğ‘¦) 1.Initialiser les paramÃ¨tres ğœƒdu modÃ¨le 2.for ğ‘’ = 1..ğ¸ 1.for ğ‘¡ = 1..ğ‘›minibatches 1.Tirer un Ã©chantillon alÃ©atoire de taillle ğ‘dans ğ’Ÿque lâ€™on appelle minibatch 2.for (ğ‘¥ğ‘–, ğ‘¦ğ‘–) âˆˆ â„¬ 1.Calculer la prÃ©diction Ì‚ ğ‘¦ğ‘–= ğ‘šğœƒ(ğ‘¥ğ‘–) 2.Calculer le gradient individuel âˆ‡ğœƒâ„’ğ‘– 3.Calculer le gradient sommÃ© sur le minibatch âˆ‡ğœƒâ„’â„¬=1 ğ‘âˆ‘ğ‘–âˆ‡ğœƒâ„’ğ‘– 4.Mettre Ã  jour les paramÃ¨tres ğœƒÃ  partir de âˆ‡ğœƒâ„’â„¬ Par consÃ©quent, lors de lâ€™utilisation de SGD, les mises Ã  jour des paramÃ¨tres sont plus frÃ©quentes, mais elles sont Â« brui- tÃ©es Â» puisquâ€™elles sont basÃ©es sur une estimation du gradient par minibatch au lieu de sâ€™appuyer sur le vrai gradient, comme illustrÃ© ci-dessous : 20 Chapitre 4. OptimisationIntroduction au Deep Learning (notes de cours) Outre le fait quâ€™elle implique des mises Ã  jour plus frÃ©quentes des paramÃ¨tres, la SGD prÃ©sente un avantage supplÃ©mentaire en termes dâ€™optimisation, qui est essentiel pour les rÃ©seaux de neurones. En effet, comme on peut le voir ci-dessous, contrairement Ã  ce que nous avions dans le cas du Perceptron, la perte MSE (et il en va de mÃªme pour la perte logistique) nâ€™est plus convexe en les paramÃ¨tres du modÃ¨le dÃ¨s que celui-ci possÃ¨de au moins une couche cachÃ©e : La descente de gradient est connue pour souffrir dâ€™optima locaux, et de tels fonctions de pertes constituent un problÃ¨me sÃ©rieux pour la descente de gradient. Dâ€™un autre cÃ´tÃ©, la descente de gradient stochastique est susceptible de bÃ©nÃ©ficier dâ€™estimations de gradient bruitÃ©es pour sâ€™Ã©chapper des minima locaux. 4.2Une note sur Adam Adam [ Kingma and Ba, 2015 ] est une variante de la mÃ©thode de descente de gradient stochastique. Elle diffÃ¨re dans la rÃ¨gle de mise Ã  jour des paramÃ¨tres. Tout dâ€™abord, elle utilise ce quâ€™on appelle le momentum, qui consiste essentiellement Ã  sâ€™appuyer sur les mises Ã  jour antÃ©rieures du gradient pour lisser la trajectoire dans lâ€™espace des paramÃ¨tres pendant lâ€™optimisation. Une illustration interactive du momentum peut Ãªtre trouvÃ©e dans [ Goh, 2017 ]. Lâ€™estimation du gradient est remplacÃ©e par la quantitÃ© : m(ğ‘¡+1)â†1 1 âˆ’ ğ›½ğ‘¡ 1[ğ›½1m(ğ‘¡)+ (1 âˆ’ ğ›½1)âˆ‡ğœƒâ„’] Lorsque ğ›½1est Ã©gal Ã  zÃ©ro, nous avons m(ğ‘¡+1)= âˆ‡ğœƒâ„’et pour ğ›½1âˆˆ]0, 1[ ,m(ğ‘¡+1)lâ€™estimation courante du gradient utilise lâ€™information sur les estimations passÃ©es, stockÃ©e dans m(ğ‘¡). Une autre diffÃ©rence importante entre SGD et la Adam consiste Ã  utiliser un taux dâ€™apprentissage adaptatif. En dâ€™autres termes, au lieu dâ€™utiliser le mÃªme taux dâ€™apprentissage ğœŒpour tous les paramÃ¨tres du modÃ¨le, le taux dâ€™apprentissage pour un paramÃ¨tre donnÃ© ğœƒğ‘–est dÃ©fini comme : Ì‚ ğœŒ(ğ‘¡+1)(ğœƒğ‘–) =ğœŒ âˆšğ‘ (ğ‘¡+1) (ğœƒğ‘–) + ğœ– oÃ¹ ğœ–est une constante petite devant 1 et ğ‘ (ğ‘¡+1)(ğœƒğ‘–) =1 1 âˆ’ ğ›½ğ‘¡ 2[ğ›½2ğ‘ (ğ‘¡)(ğœƒğ‘–) + (1 âˆ’ ğ›½2) (âˆ‡ğœƒğ‘–â„’)2] 4.2. Une note sur Adam 21Introduction au Deep Learning (notes de cours) Ici aussi, le terme ğ‘ utilise le momentum. Par consÃ©quent, le taux dâ€™apprentissage sera rÃ©duit pour les paramÃ¨tres qui ont subi de grandes mises Ã  jour dans les itÃ©rations prÃ©cÃ©dentes. Globalement, la rÃ¨gle de mise Ã  jour dâ€™Adam est la suivante : ğœƒ(ğ‘¡+1)â† ğœƒ(ğ‘¡)âˆ’ Ì‚ ğœŒ(ğ‘¡+1)(ğœƒ)m(ğ‘¡+1) 4.3La malÃ©diction de la profondeur ConsidÃ©rons le rÃ©seau neuronal suivant : w(0)w(1)w(2) et rappelons que, pour une couche donnÃ©e (â„“), la sortie de la couche est calculÃ©e comme suit ğ‘(â„“)= ğœ‘(ğ‘œ(â„“)) = ğœ‘(ğ‘¤(â„“âˆ’1)ğ‘(â„“âˆ’1)) oÃ¹ ğœ‘est la fonction dâ€™activation pour la couche donnÃ©e (nous ignorons les termes de biais dans cet exemple simplifiÃ©). Afin dâ€™effectuer une descente de gradient (stochastique), les gradients de la perte par rapport aux paramÃ¨tres du modÃ¨le doivent Ãªtre calculÃ©s. En utilisant la rÃ¨gle de la dÃ©rivation en chaÃ®ne, ces gradients peuvent Ãªtre exprimÃ©s comme suit : ğœ•â„’ ğœ•ğ‘¤(2)=ğœ•â„’ ğœ•ğ‘(3)ğœ•ğ‘(3) ğœ•ğ‘œ(3)ğœ•ğ‘œ(3) ğœ•ğ‘¤(2) ğœ•â„’ ğœ•ğ‘¤(1)=ğœ•â„’ ğœ•ğ‘(3)ğœ•ğ‘(3) ğœ•ğ‘œ(3)ğœ•ğ‘œ(3) ğœ•ğ‘(2)ğœ•ğ‘(2) ğœ•ğ‘œ(2)ğœ•ğ‘œ(2) ğœ•ğ‘¤(1) ğœ•â„’ ğœ•ğ‘¤(0)=ğœ•â„’ ğœ•ğ‘(3)ğœ•ğ‘(3) ğœ•ğ‘œ(3)ğœ•ğ‘œ(3) ğœ•ğ‘(2)ğœ•ğ‘(2) ğœ•ğ‘œ(2)ğœ•ğ‘œ(2) ğœ•ğ‘(1)ğœ•ğ‘(1) ğœ•ğ‘œ(1)ğœ•ğ‘œ(1) ğœ•ğ‘¤(0) Il y a des idÃ©es importantes Ã  saisir ici. Tout dâ€™abord, il faut remarquer que les poids qui sont plus Ã©loignÃ©s de la sortie du modÃ¨le hÃ©ritent de rÃ¨gles de gradient composÃ©es de plus de termes. Par consÃ©quent, lorsque certains de ces termes deviennent de plus en plus petits, il y a un risque plus Ã©levÃ© pour ces poids que leurs gradients tombent Ã  0. Câ€™est ce quâ€™on appelle lâ€™effet de gradient Ã©vanescent (vanishing gradient ), qui est un phÃ©nomÃ¨ne trÃ¨s courant dans les rÃ©seaux neuronaux profonds (câ€™est-Ã -dire les rÃ©seaux composÃ©s de nombreuses couches). 22 Chapitre 4. OptimisationIntroduction au Deep Learning (notes de cours) DeuxiÃ¨mement, certains termes sont rÃ©pÃ©tÃ©s dans ces formules, et en gÃ©nÃ©ral, des termes de la formeğœ•ğ‘(â„“) ğœ•ğ‘œ(â„“)etğœ•ğ‘œ(â„“) ğœ•ğ‘(â„“âˆ’1)sont prÃ©sents Ã  plusieurs endroits. Ces termes peuvent Ãªtre dÃ©veloppÃ©s comme suit : ğœ•ğ‘(â„“) ğœ•ğ‘œ(â„“)= ğœ‘â€²(ğ‘œ(â„“)) ğœ•ğ‘œ(â„“) ğœ•ğ‘(â„“âˆ’1)= ğ‘¤(â„“âˆ’1) Voyons Ã  quoi ressemblent les dÃ©rivÃ©es des fonctions dâ€™activation standard : On peut constater que la dÃ©rivÃ©e de ReLU possÃ¨de une plus grande plage de valeurs dâ€™entrÃ©e pour lesquelles elle est non nulle (typiquement toute la plage de valeurs dâ€™entrÃ©e positives) que ses concurrentes, ce qui en fait une fonction dâ€™activation trÃ¨s intÃ©ressante pour les rÃ©seaux neuronaux profonds, car nous avons vu que le termeğœ•ğ‘(â„“) ğœ•ğ‘œ(â„“)apparaÃ®t de maniÃ¨re rÃ©pÃ©tÃ©e dans les dÃ©rivations en chaÃ®ne. 4.4Coder tout cela en keras Dans keras , les informations sur les pertes et lâ€™optimiseur sont transmises au moment de la compilation : import keras_core askeras from keras .layers import Dense, InputLayer from keras .models import Sequential model =Sequential([ InputLayer(input_shape =(10, )), Dense(units =20, activation =\"relu \"), Dense(units =3, activation =\"softmax \") ]) model .summary() Using TensorFlow backend Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 20) 220 (suite sur la page suivante) 4.4. Coder tout cela en keras 23Introduction au Deep Learning (notes de cours) (suite de la page prÃ©cÃ©dente) dense_1 (Dense) (None, 3) 63 ================================================================= Total params: 283 (1.11 KB) Trainable params: 283 (1.11 KB) Non-trainable params: 0 (0.00 Byte) _________________________________________________________________ model .compile(loss =\"categorical_crossentropy \", optimizer =\"adam \") En termes de pertes : â€”\"mse\" est la perte dâ€™erreur quadratique moyenne, â€”\"binary_crossentropy\" est la perte logistique pour la classification binaire, â€”\"categorical_crossentropy\" est la perte logistique pour la classification multi-classes. Les optimiseurs dÃ©finis dans cette section sont disponibles sous forme de \"sgd\" et\"adam\" . Afin dâ€™avoir le contrÃ´le sur les hyper-paramÃ¨tres des optimiseurs, on peut alternativement utiliser la syntaxe suivante : from keras .optimizers import Adam, SGD # Not a very good idea to tune beta_1 # and beta_2 parameters in Adam adam_opt =Adam(learning_rate =0.001 , beta_1 =0.9, beta_2 =0.9) # In order to use SGD with a custom learning rate: # sgd_opt = SGD(learning_rate=0.001) model .compile(loss =\"categorical_crossentropy \", optimizer =adam_opt) 4.5PrÃ©traitement des donnÃ©es En pratique, pour que la phase dâ€™ajustement du modÃ¨le se dÃ©roule correctement, il est important de mettre Ã  lâ€™Ã©chelle les donnÃ©es dâ€™entrÃ©e. Dans lâ€™exemple suivant, nous allons comparer deux entraÃ®nements du mÃªme modÃ¨le, avec une initiali- sation similaire et la seule diffÃ©rence entre les deux sera de savoir si les donnÃ©es dâ€™entrÃ©e sont centrÃ©es-rÃ©duites ou laissÃ©es telles quelles. import pandas aspd from keras .utils import to_categorical iris =pd.read_csv( \"../data/iris.csv \", index_col =0) iris =iris .sample(frac =1) y=to_categorical(iris[ \"target \"]) X=iris .drop(columns =[\"target \"]) from keras .layers import Dense, InputLayer from keras .models import Sequential from keras .utils import set_random_seed (suite sur la page suivante) 24 Chapitre 4. OptimisationIntroduction au Deep Learning (notes de cours) (suite de la page prÃ©cÃ©dente) set_random_seed( 0) model =Sequential([ InputLayer(input_shape =(4, )), Dense(units =256, activation =\"relu \"), Dense(units =256, activation =\"relu \"), Dense(units =256, activation =\"relu \"), Dense(units =3, activation =\"softmax \") ]) n_epochs =100 model .compile(loss =\"categorical_crossentropy \", optimizer =\"adam \", metrics =[\"accuracy \"]) h=model .fit(X, y, epochs =n_epochs, batch_size =30, verbose =0) Standardisons maintenant nos donnÃ©es et comparons les performances obtenues : X-=X.mean(axis =0) X/=X.std(axis =0) set_random_seed( 0) model =Sequential([ InputLayer(input_shape =(4, )), Dense(units =256, activation =\"relu \"), Dense(units =256, activation =\"relu \"), Dense(units =256, activation =\"relu \"), Dense(units =3, activation =\"softmax \") ]) n_epochs =100 model .compile(loss =\"categorical_crossentropy \", optimizer =\"adam \", metrics =[\"accuracy \"]) h_standardized =model .fit(X, y, epochs =n_epochs, batch_size =30, verbose =0) 4.5. PrÃ©traitement des donnÃ©es 25Introduction au Deep Learning (notes de cours) 26 Chapitre 4. OptimisationCHAPITRE 5 RÃ‰GULARISATION Comme nous lâ€™avons vu dans les chapitres prÃ©cÃ©dents, lâ€™une des forces des rÃ©seaux neuronaux est quâ€™ils peuvent approximer nâ€™importe quelle fonction continue lorsquâ€™un nombre suffisant de paramÃ¨tres est utilisÃ©. Lors de lâ€™utilisation dâ€™approxima- teurs universels dans des contextes dâ€™apprentissage automatique, un risque connexe important est celui du surajustement (overfitting ) aux donnÃ©es dâ€™apprentissage. Plus formellement, Ã©tant donnÃ© un jeu de donnÃ©es dâ€™apprentissage ğ’Ÿğ‘¡tirÃ© dâ€™une distribution inconnue ğ’Ÿ, les paramÃ¨tres du modÃ¨le sont optimisÃ©s de maniÃ¨re Ã  minimiser le risque empirique : â„›ğ‘’(ğœƒ) =1 |ğ’Ÿğ‘¡|âˆ‘ (ğ‘¥ğ‘–,ğ‘¦ğ‘–)âˆˆğ’Ÿğ‘¡â„’(ğ‘¥ğ‘–, ğ‘¦ğ‘–; ğ‘šğœƒ) alors que le vÃ©ritable objectif est de minimiser le Â« vrai Â» risque : â„›(ğœƒ) = ğ”¼ğ‘¥,ğ‘¦âˆ¼ğ’Ÿ â„’(ğ‘¥, ğ‘¦; ğ‘šğœƒ) et les deux objectifs nâ€™ont pas le mÃªme minimiseur. Pour Ã©viter cet Ã©cueil, il faut utiliser des techniques de rÃ©gularisation, telles que celles prÃ©sentÃ©es ci-aprÃ¨s. 5.1Early stopping Comme illustrÃ© ci-dessous, on peut observer que lâ€™entraÃ®nement dâ€™un rÃ©seau neuronal pendant un trop grand nombre dâ€epochs peut conduire Ã  un surajustement. Notez quâ€™ici, le risque rÃ©el est estimÃ© grÃ¢ce Ã  lâ€™utilisation dâ€™un ensemble de validation qui nâ€™est pas vu pendant lâ€™entraÃ®nement. Using TensorFlow backend iris =pd.read_csv( \"../data/iris.csv \", index_col =0) iris =iris .sample(frac =1) y=to_categorical(iris[ \"target \"]) X=iris .drop(columns =[\"target \"]) X-=X.mean(axis =0) X/=X.std(axis =0) 27Introduction au Deep Learning (notes de cours) import keras_core askeras from keras .layers import Dense, InputLayer from keras .models import Sequential from keras .utils import set_random_seed set_random_seed( 0) model =Sequential([ InputLayer(input_shape =(4, )), Dense(units =256, activation =\"relu \"), Dense(units =256, activation =\"relu \"), Dense(units =256, activation =\"relu \"), Dense(units =3, activation =\"softmax \") ]) n_epochs =100 model .compile(loss =\"categorical_crossentropy \", optimizer =\"adam \", metrics =[\"accuracy \"]) h=model .fit(X, y, validation_split =0.3, epochs =n_epochs, batch_size =30, verbose =0) Ici, le meilleur modÃ¨le (en termes de capacitÃ©s de gÃ©nÃ©ralisation) semble Ãªtre le modÃ¨le Ã  lâ€ epoch 30. En dâ€™autres termes, si nous avions arrÃªtÃ© le processus dâ€™apprentissage aprÃ¨s lâ€ epoch 30, nous aurions obtenu un meilleur modÃ¨le que si nous utilisons le modÃ¨le entraÃ®nÃ© pendant 70 epochs . Câ€™est toute lâ€™idÃ©e derriÃ¨re la stratÃ©gie dâ€ early stopping , qui consiste Ã  arrÃªter le processus dâ€™apprentissage dÃ¨s que la perte de validation cesse de sâ€™amÃ©liorer. Cependant, comme on peut le voir dans la visualisation ci-dessus, la perte de validation a tendance Ã  osciller, et on attend souvent plusieurs epochs avant de supposer que la perte a peu de chances de sâ€™amÃ©liorer dans le futur. Le nombre dâ€ epochs Ã  attendre est appelÃ© le paramÃ¨tre de patience . Dans keras , lâ€™arrÃªt anticipÃ© peut Ãªtre configurÃ© via un callback , comme dans lâ€™exemple suivant : from keras .callbacks import EarlyStopping set_random_seed( 0) model =Sequential([ InputLayer(input_shape =(4, )), (suite sur la page suivante) 28 Chapitre 5. RÃ©gularisationIntroduction au Deep Learning (notes de cours) (suite de la page prÃ©cÃ©dente) Dense(units =256, activation =\"relu \"), Dense(units =256, activation =\"relu \"), Dense(units =256, activation =\"relu \"), Dense(units =3, activation =\"softmax \") ]) cb_es =EarlyStopping(monitor =\"val_loss \", patience =10, restore_best_weights =True ) n_epochs =100 model .compile(loss =\"categorical_crossentropy \", optimizer =\"adam \", metrics =[\"accuracy \"]) h=model .fit(X, y, validation_split =0.3, epochs =n_epochs, batch_size =30, verbose =0, callbacks =[cb_es]) Et maintenant, mÃªme si le modÃ¨le Ã©tait prÃ©vu pour Ãªtre entraÃ®nÃ© pendant 70 epochs , lâ€™entraÃ®nement est arrÃªtÃ© dÃ¨s quâ€™il atteint 10 epochs consÃ©cutives sans amÃ©lioration de la perte de validation, et les paramÃ¨tres du modÃ¨le sont restaurÃ©s comme les paramÃ¨tres du modÃ¨le Ã  lâ€ epoch 30. 5.2PÃ©nalisation de la perte Une autre faÃ§on importante dâ€™appliquer la rÃ©gularisation dans les rÃ©seaux neuronaux est la pÃ©nalisation des pertes. Un exemple typique de cette stratÃ©gie de rÃ©gularisation est la rÃ©gularisation L2. Si nous dÃ©signons par â„’ğ‘Ÿla perte rÃ©gularisÃ©e par L2, elle peut Ãªtre exprimÃ©e comme suit : â„’ğ‘Ÿ(ğ’Ÿ; ğ‘šğœƒ) = â„’(ğ’Ÿ; ğ‘šğœƒ) + ğœ† âˆ‘ â„“â€–ğœƒ(â„“)â€–2 2 oÃ¹ ğœƒ(â„“)est la matrice de poids de la couche â„“. Cette rÃ©gularisation tend Ã  rÃ©duire les grandes valeurs des paramÃ¨tres pendant le processus dâ€™apprentissage, ce qui est connu pour aider Ã  amÃ©liorer la gÃ©nÃ©ralisation. Enkeras , ceci est implÃ©mentÃ© comme : 5.2. PÃ©nalisation de la perte 29Introduction au Deep Learning (notes de cours) from keras .regularizers import L2 Î»=0.01 set_random_seed( 0) model =Sequential([ InputLayer(input_shape =(4, )), Dense(units =256, activation =\"relu \", kernel_regularizer =L2(Î»)), Dense(units =256, activation =\"relu \", kernel_regularizer =L2(Î»)), Dense(units =256, activation =\"relu \", kernel_regularizer =L2(Î»)), Dense(units =3, activation =\"softmax \") ]) n_epochs =100 model .compile(loss =\"categorical_crossentropy \", optimizer =\"adam \", metrics =[\"accuracy \"]) h=model .fit(X, y, validation_split =0.3, epochs =n_epochs, batch_size =30, verbose =0) 5.3DropOut Dans cette section, nous prÃ©sentons la stratÃ©gie DropOut , qui a Ã©tÃ© introduite dans [ Srivastava et al., 2014 ]. Lâ€™idÃ©e derriÃ¨re leDropOut est dâ€™Ã©teindre certains neurones pendant lâ€™apprentissage. Les neurones dÃ©sactivÃ©s changent Ã  chaque minibatch de sorte que, globalement, tous les neurones sont entraÃ®nÃ©s pendant tout le processus. Le concept est trÃ¨s similaire dans lâ€™esprit Ã  une stratÃ©gie utilisÃ©e pour lâ€™entraÃ®nement des forÃªts alÃ©atoires, qui consiste Ã  sÃ©lectionner alÃ©atoirement des variables candidates pour chaque division dâ€™arbre Ã  lâ€™intÃ©rieur dâ€™une forÃªt, ce qui est connu pour conduire Ã  de meilleures performances de gÃ©nÃ©ralisation pour les forÃªts alÃ©atoires. La principale diffÃ©rence ici est que lâ€™on peut non seulement dÃ©sactiver les neurones dâ€™entrÃ©e mais aussi les neurones de la couche cachÃ©e pendant lâ€™apprentissage. Danskeras , ceci est implÃ©mentÃ© comme une couche, qui agit en dÃ©sactivant les neurones de la couche prÃ©cÃ©dente dans le rÃ©seau : 30 Chapitre 5. RÃ©gularisationIntroduction au Deep Learning (notes de cours) FIG. 5.1 â€“ Illustration du mÃ©canisme de DropOut . Afin dâ€™entraÃ®ner un modÃ¨le donnÃ© (Ã  gauche), Ã  chaque minibatch , une proportion donnÃ©e de neurones est choisie au hasard pour Ãªtre Â« dÃ©sactivÃ©e Â» et le sous-rÃ©seau rÃ©sultant est utilisÃ© pour lâ€™Ã©tape dâ€™optimisation en cours ( cf.figure de droite, dans laquelle 40% des neurones â€“ colorÃ©s en gris â€“ sont dÃ©sactivÃ©s). from keras .layers import Dropout set_random_seed( 0) switchoff_proba =0.3 model =Sequential([ InputLayer(input_shape =(4, )), Dropout(rate =switchoff_proba), Dense(units =256, activation =\"relu \"), Dropout(rate =switchoff_proba), Dense(units =256, activation =\"relu \"), Dropout(rate =switchoff_proba), Dense(units =256, activation =\"relu \"), Dropout(rate =switchoff_proba), Dense(units =3, activation =\"softmax \") ]) n_epochs =100 model .compile(loss =\"categorical_crossentropy \", optimizer =\"adam \", metrics =[\"accuracy \"]) h=model .fit(X, y, validation_split =0.3, epochs =n_epochs, batch_size =30, verbose =0) 5.3.DropOut 31Introduction au Deep Learning (notes de cours) Exercice #1 En observant les valeurs de perte dans la figure ci-dessus, pouvez-vous expliquer pourquoi la perte de validation est presque systÃ©matiquement infÃ©rieure Ã  celle calculÃ©e sur le jeu dâ€™apprentissage? Solution En fait, la perte dâ€™apprentissage est calculÃ©e comme la perte moyenne sur tous les minibatchs dâ€™apprentissage pendant une epoch . Si nous nous rappelons que pendant lâ€™apprentissage, Ã  chaque minibatch , 30% des neurones sont dÃ©sactivÃ©s, on peut voir que seule une sous-partie du modÃ¨le complet est utilisÃ©e lors de lâ€™Ã©valuation de la perte dâ€™apprentissage alors que le modÃ¨le complet est utilisÃ© lors de la prÃ©diction sur lâ€™ensemble de validation, ce qui explique pourquoi la perte de validation mesurÃ©e est infÃ©rieure Ã  celle de lâ€™apprentissage. 32 Chapitre 5. RÃ©gularisationCHAPITRE 6 RÃ‰SEAUX NEURONAUX CONVOLUTIFS Les rÃ©seaux de neurones convolutifs (aussi appelÃ©s ConvNets) sont conÃ§us pour tirer parti de la structure des donnÃ©es. Dans ce chapitre, nous aborderons deux types de rÃ©seaux convolutifs : nous commencerons par le cas monodimensionnel et verrons comment les rÃ©seaux convolutifs Ã  convolutions 1D peuvent Ãªtre utiles pour traiter les sÃ©ries temporelles. Nous prÃ©senterons ensuite le cas 2D, particuliÃ¨rement utile pour traiter les donnÃ©es dâ€™image. 6.1RÃ©seaux de neurones convolutifs pour les sÃ©ries temporelles Les rÃ©seaux de neurones convolutifs pour les sÃ©ries temporelles reposent sur lâ€™opÃ©rateur de convolution 1D qui, Ã©tant donnÃ© une sÃ©rie temporelle xet un filtre f, calcule une carte dâ€™activation comme : (xâˆ—f) (ğ‘¡) =ğ¿ âˆ‘ ğ‘˜=âˆ’ğ¿ğ‘“ğ‘˜ğ‘¥ğ‘¡+ğ‘˜ (6.1) oÃ¹ le filtre fest de longueur (2ğ¿ + 1) . Le code suivant illustre cette notion en utilisant un filtre gaussien : Les rÃ©seaux de neurones convolutifs sont constituÃ©s de blocs de convolution dont les paramÃ¨tres sont les coefficients des filtres quâ€™ils intÃ¨grent (les filtres ne sont donc pas fixÃ©s a priori comme dans lâ€™exemple ci-dessus mais plutÃ´t appris). Ces blocs de convolution sont Ã©quivariants par translation, ce qui signifie quâ€™un dÃ©calage (temporel) de leur entrÃ©e entraÃ®ne le mÃªme dÃ©calage temporel de leur sortie : /tmp/ipykernel_14514/1028966743.py:32: UserWarning: This figure includes Axes that â£ â†ªare not compatible with tight_layout, so results might be incorrect. plt.tight_layout() /tmp/ipykernel_14514/1028966743.py:23: MatplotlibDeprecationWarning: Auto-removal â£ â†ªof overlapping axes is deprecated since 3.6 and will be removed two minor â£ â†ªreleases later; explicitly call ax.remove() as needed. fig2 = plt.subplot(2, 1, 2) /tmp/ipykernel_14514/1028966743.py:32: UserWarning: The figure layout has changed â£ â†ªto tight plt.tight_layout() 33Introduction au Deep Learning (notes de cours)  Les modÃ¨les convolutifs sont connus pour Ãªtre trÃ¨s performants dans les applications de vision par ordinateur, utilisant des quantitÃ©s modÃ©rÃ©es de paramÃ¨tres par rapport aux modÃ¨les entiÃ¨rement connectÃ©s (bien sÃ»r, des contre-exemples existent, et le terme Â« modÃ©rÃ© Â» est particuliÃ¨rement vague). La plupart des architectures standard de sÃ©ries temporelles qui reposent sur des blocs convolutionnels sont des adaptations directes de modÃ¨les de la communautÃ© de la vision par ordinateur ([ Le Guennec et al., 2016 ] sâ€™appuie sur une alternance entre couches de convolution et couches de pooling , tandis que des travaux plus rÃ©cents sâ€™appuient sur des connexions rÃ©siduelles et des modules dâ€ inception [Fawaz et al., 2020 ]). Ces blocs de base (convolution, pooling, couches rÃ©siduelles) sont discutÃ©s plus en dÃ©tail dans la section suivante. Ces modÃ¨les de classification des sÃ©ries temporelles (et bien dâ€™autres) sont prÃ©sentÃ©s et Ã©valuÃ©s dans [ Fawaz et al., 2019 ] que nous conseillons au lecteur intÃ©ressÃ©. 6.2RÃ©seaux de neurones convolutifs pour les images Nous allons maintenant nous intÃ©resser au cas 2D, dans lequel les filtres de convolution ne glisseront pas sur un seul axe comme dans le cas des sÃ©ries temporelles, mais plutÃ´t sur les deux dimensions (largeur et hauteur) dâ€™une image. 6.2.1Images et convolutions Comme on le voit ci-dessous, une image est une grille de pixels, et chaque pixel a une valeur dâ€™intensitÃ© dans chacun des canaux de lâ€™image. Les images couleur sont typiquement composÃ©es de 3 canaux (ici Rouge, Vert et Bleu). FIG. 6.1 â€“ Une image et ses 3 canaux (intensitÃ©s de Rouge, Vert et Bleu, de gauche Ã  droite). La sortie dâ€™une convolution sur une image xest une nouvelle image, dont les valeurs des pixels peuvent Ãªtre calculÃ©es comme suit : (xâˆ—f) (ğ‘–, ğ‘—) =ğ¾ âˆ‘ ğ‘˜=âˆ’ğ¾ğ¿ âˆ‘ ğ‘™=âˆ’ğ¿3 âˆ‘ ğ‘=1ğ‘“ğ‘˜,ğ‘™,ğ‘ ğ‘¥ğ‘–+ğ‘˜,ğ‘—+ğ‘™,ğ‘ . (6.2) 34 Chapitre 6. RÃ©seaux neuronaux convolutifsIntroduction au Deep Learning (notes de cours) En dâ€™autres termes, les pixels de lâ€™image de sortie sont calculÃ©s comme le produit scalaire entre un filtre de convolution (qui est un tenseur de forme (2ğ¾ + 1, 2ğ¿ + 1, ğ‘) ) et un patch dâ€™image centrÃ© Ã  la position donnÃ©e. ConsidÃ©rons, par exemple, le filtre de convolution 9x9 suivant : Le rÃ©sultat de la convolution de lâ€™image de chat ci-dessus avec ce filtre est lâ€™image suivante en niveaux de gris (câ€™est-Ã -dire constituÃ©e dâ€™un seul canal) : 6.2. RÃ©seaux de neurones convolutifs pour les images 35Introduction au Deep Learning (notes de cours) On peut remarquer que cette image est une version floue de lâ€™image originale. Câ€™est parce que nous avons utilisÃ© un filtre Gaussien. Comme pour les sÃ©ries temporelles, lors de lâ€™utilisation dâ€™opÃ©rations de convolution dans les rÃ©seaux neuronaux, le contenu des filtres sera appris, plutÃ´t que dÃ©fini a priori . 6.2.2RÃ©seaux convolutifs de type LeNet Dans [ LeCun et al., 1998 ], un empilement de couches de convolution, de pooling et de couches entiÃ¨rement connectÃ©es est introduit pour une tÃ¢che de classification dâ€™images, plus spÃ©cifiquement une application de reconnaissance de chiffres. Le rÃ©seau neuronal rÃ©sultant, appelÃ© LeNet, est reprÃ©sentÃ© ci-dessous : FIG. 6.2 â€“ ModÃ¨le LeNet-5 Couches de convolution Une couche de convolution est constituÃ©e de plusieurs filtres de convolution (Ã©galement appelÃ©s kernels ) qui opÃ¨rent en parallÃ¨le sur la mÃªme image dâ€™entrÃ©e. Chaque filtre de convolution gÃ©nÃ¨re une carte dâ€™activation en sortie et toutes ces cartes sont empilÃ©es pour former la sortie de la couche de convolution. Tous les filtres dâ€™une couche partagent la mÃªme largeur et la mÃªme hauteur. Un terme de biais et une fonction dâ€™activation peuvent Ãªtre utilisÃ©s dans les couches de convolution, comme dans dâ€™autres couches de rÃ©seaux neuronaux. Dans lâ€™ensemble, la sortie dâ€™un filtre de convolution est calculÃ©e comme suit : (xâˆ—f) (ğ‘–, ğ‘—, ğ‘) = ğœ‘ (ğ¾ âˆ‘ ğ‘˜=âˆ’ğ¾ğ¿ âˆ‘ ğ‘™=âˆ’ğ¿âˆ‘ ğ‘â€²ğ‘“ğ‘ ğ‘˜,ğ‘™,ğ‘â€²ğ‘¥ğ‘–+ğ‘˜,ğ‘—+ğ‘™,ğ‘â€²+ ğ‘ğ‘) (6.3) oÃ¹ ğ‘dÃ©signe le canal de sortie (notez que chaque canal de sortie est associÃ© Ã  un filtre ğ‘“ğ‘),ğ‘ğ‘est le terme de biais qui lui est associÃ© et ğœ‘est la fonction dâ€™activation utilisÃ©e. Astuce: Enkeras , une telle couche est implÃ©mentÃ©e Ã  lâ€™aide de la classe Conv2D : import keras_core askeras from keras .layers import Conv2D layer =Conv2D(filters =6, kernel_size =5, padding =\"valid \", activation =\"relu \") Padding 36 Chapitre 6. RÃ©seaux neuronaux convolutifsIntroduction au Deep Learning (notes de cours) FIG. 6.3 â€“ Visualisation de lâ€™effet du padding (source: V. Dumoulin, F. Visin - A guide to convolution arithmetic for deep learning ). Gauche: sans padding , droite: avec padding . Lors du traitement dâ€™une image dâ€™entrÃ©e, il peut Ãªtre utile de sâ€™assurer que la carte de caractÃ©ristiques (ou carte dâ€™activation) de sortie a la mÃªme largeur et la mÃªme hauteur que lâ€™image dâ€™entrÃ©e. Cela peut Ãªtre rÃ©alisÃ© en agrandissant artificiellement lâ€™image dâ€™entrÃ©e et en remplissant les zones ajoutÃ©es avec des zÃ©ros, comme illustrÃ© dans Fig. 6.3 dans lequel la zone de padding est reprÃ©sentÃ©e en blanc. Couches de pooling Les couches de pooling effectuent une opÃ©ration de sous-Ã©chantillonnage qui rÃ©sume en quelque sorte les informations contenues dans les cartes de caractÃ©ristiques dans des cartes Ã  plus faible rÃ©solution. Lâ€™idÃ©e est de calculer, pour chaque parcelle dâ€™image, une caractÃ©ristique de sortie qui calcule un agrÃ©gat des pixels de la parcelle. Les opÃ©rateurs dâ€™agrÃ©gation typiques sont les opÃ©rateurs de moyenne (dans ce cas, la couche correspondante est appelÃ©e average pooling ) ou de maximum (pour les couches de max pooling ). Afin de rÃ©duire la rÃ©solution des cartes de sortie, ces agrÃ©gats sont gÃ©nÃ©ralement calculÃ©s sur des fenÃªtres glissantes qui ne se chevauchent pas, comme illustrÃ© ci-dessous, pour un max pooling avec une taille de pooling de 2x2 : 6.2. RÃ©seaux de neurones convolutifs pour les images 37Introduction au Deep Learning (notes de cours) max Ces couches Ã©taient largement utilisÃ©es historiquement dans les premiers modÃ¨les convolutifs et le sont de moins en moins Ã  mesure que la puissance de calcul disponible augmente. Astuce: Enkeras , les couches de pooling sont implÃ©mentÃ©es Ã  travers les classes MaxPool2D etAvgPool2D : from keras .layers import MaxPool2D, AvgPool2D max_pooling_layer =MaxPool2D(pool_size =2) average_pooling_layer =AvgPool2D(pool_size =2) Ajout dâ€™une tÃªte de classification Un empilement de couches de convolution et de pooling produit une carte dâ€™activation structurÃ©e (qui prend la forme dâ€™une grille 2d avec une dimension supplÃ©mentaire pour les diffÃ©rents canaux). Lorsque lâ€™on vise une tÃ¢che de classification dâ€™images, lâ€™objectif est de produire la classe la plus probable pour lâ€™image dâ€™entrÃ©e, ce qui est gÃ©nÃ©ralement rÃ©alisÃ© par une tÃªte de classification ( classification head ) composÃ©e de couches entiÃ¨rement connectÃ©es. Pour que la tÃªte de classification soit capable de traiter une carte dâ€™activation, les informations de cette carte doivent Ãªtre transformÃ©es en un vecteur. Cette opÃ©ration est appelÃ©e Flatten danskeras , et le modÃ¨le correspondant Ã  Fig. 6.2 peut Ãªtre implÃ©mentÃ© comme : from keras .models import Sequential from keras .layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense model =Sequential([ (suite sur la page suivante) 38 Chapitre 6. RÃ©seaux neuronaux convolutifsIntroduction au Deep Learning (notes de cours) (suite de la page prÃ©cÃ©dente) InputLayer(input_shape =(32,32,1)), Conv2D(filters =6, kernel_size =5, padding =\"valid \", activation =\"relu \"), MaxPool2D(pool_size =2), Conv2D(filters =16, kernel_size =5, padding =\"valid \", activation =\"relu \"), MaxPool2D(pool_size =2), Flatten(), Dense( 120, activation =\"relu \"), Dense( 84, activation =\"relu \"), Dense( 10, activation =\"softmax \") ]) model .summary() Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 28, 28, 6) 156 max_pooling2d (MaxPooling2 (None, 14, 14, 6) 0 D) conv2d_1 (Conv2D) (None, 10, 10, 16) 2416 max_pooling2d_1 (MaxPoolin (None, 5, 5, 16) 0 g2D) flatten (Flatten) (None, 400) 0 dense (Dense) (None, 120) 48120 dense_1 (Dense) (None, 84) 10164 dense_2 (Dense) (None, 10) 850 ================================================================= Total params: 61706 (241.04 KB) Trainable params: 61706 (241.04 KB) Non-trainable params: 0 (0.00 Byte) _________________________________________________________________ 6.2. RÃ©seaux de neurones convolutifs pour les images 39Introduction au Deep Learning (notes de cours) 40 Chapitre 6. RÃ©seaux neuronaux convolutifsCHAPITRE 7 RÃ‰SEAUX NEURONAUX RÃ‰CURRENTS Les rÃ©seaux neuronaux rÃ©currents (RNN) traitent les Ã©lÃ©ments dâ€™une sÃ©rie temporelle un par un. Typiquement, Ã  lâ€™instant ğ‘¡, un bloc rÃ©current prend en entrÃ©e : â€”lâ€™entrÃ©e courante ğ‘¥ğ‘¡et â€”un Ã©tat cachÃ© â„ğ‘¡âˆ’1qui a pour but de rÃ©sumer les informations clÃ©s provenant de des entrÃ©es passÃ©es {ğ‘¥0, â€¦ , ğ‘¥ğ‘¡âˆ’1 } Ce bloc retourne un Ã©tat cachÃ© mis Ã  jour â„ğ‘¡: â€¦ â€¦â„ğ‘¡ ğ‘¥ğ‘¡â„ğ‘¡âˆ’1 ğ‘¥ğ‘¡âˆ’1â„ğ‘¡+1 ğ‘¥ğ‘¡+1 Il existe diffÃ©rentes couches rÃ©currentes qui diffÃ¨rent principalement par la faÃ§on dont â„ğ‘¡est calculÃ©e. 41Introduction au Deep Learning (notes de cours) 7.1RÃ©seaux rÃ©currents standard La formulation originale dâ€™une RNN est la suivante : âˆ€ğ‘¡, â„ğ‘¡=tanh (ğ‘Šâ„â„ğ‘¡âˆ’1 + ğ‘Šğ‘¥ğ‘¥ğ‘¡+ ğ‘) (7.1) oÃ¹ ğ‘Šâ„est une matrice de poids associÃ©e au traitement de lâ€™Ã©tat cachÃ© prÃ©cÃ©dent, ğ‘Šğ‘¥est une autre matrice de poids associÃ©e au traitement de la lâ€™entrÃ©e actuelle et ğ‘est un terme de biais. On notera ici que ğ‘Šâ„,ğ‘Šğ‘¥etğ‘ne sont pas indexÃ©s par ğ‘¡, ce qui signifie que quâ€™ils sont partagÃ©s entre tous les temps . Une limitation importante de cette formule est quâ€™elle Ã©choue Ã  capturer les dÃ©pendances Ã  long terme. Pour mieux comprendre pourquoi, il faut se rappeler que les paramÃ¨tres de ces rÃ©seaux sont optimisÃ©s par des algorithmes de descente de gradient stochastique. Pour simplifier les notations, considÃ©rons un cas simplifiÃ© dans lequel â„ğ‘¡etğ‘¥ğ‘¡sont tous deux des valeurs scalaires, et regardons ce que vaut le gradient de la sortie â„ğ‘¡par rapport Ã  ğ‘Šâ„(qui est alors aussi un scalaire) : âˆ‡ğ‘Šâ„(â„ğ‘¡) =tanhâ€²(ğ‘œğ‘¡) â‹…ğœ•ğ‘œğ‘¡ ğœ•ğ‘Šâ„(7.2) oÃ¹ ğ‘œğ‘¡= ğ‘Šâ„â„ğ‘¡âˆ’1 + ğ‘Šğ‘¥ğ‘¥ğ‘¡+ ğ‘, donc: ğœ•ğ‘œğ‘¡ ğœ•ğ‘Šâ„= â„ğ‘¡âˆ’1 + ğ‘Šâ„â‹…ğœ•â„ğ‘¡âˆ’1 ğœ•ğ‘Šâ„. (7.3) Ici, la forme değœ•â„ğ‘¡âˆ’1 ğœ•ğ‘Šâ„sera similaire Ã  celle de âˆ‡ğ‘Šâ„(â„ğ‘¡)ci-dessus, et, au final, on obtient : âˆ‡ğ‘Šâ„(â„ğ‘¡) = tanhâ€²(ğ‘œğ‘¡) â‹… [â„ğ‘¡âˆ’1 + ğ‘Šâ„â‹…ğœ•â„ğ‘¡âˆ’1 ğœ•ğ‘Šâ„] (7.4) =tanhâ€²(ğ‘œğ‘¡) â‹… [â„ğ‘¡âˆ’1 + ğ‘Šâ„â‹…tanhâ€²(ğ‘œğ‘¡âˆ’1 ) â‹… [â„ğ‘¡âˆ’2 + ğ‘Šâ„â‹… [â€¦ ]]] (7.5) = â„ğ‘¡âˆ’1tanhâ€²(ğ‘œğ‘¡) + â„ğ‘¡âˆ’2 ğ‘Šâ„tanhâ€²(ğ‘œğ‘¡)tanhâ€²(ğ‘œğ‘¡âˆ’1 ) + â€¦ (7.6) =ğ‘¡âˆ’1 âˆ‘ ğ‘¡â€²=1â„ğ‘¡â€²[ğ‘Šğ‘¡âˆ’ğ‘¡â€²âˆ’1 â„ tanhâ€²(ğ‘œğ‘¡â€²+1) â‹… â‹¯ â‹… tanhâ€²(ğ‘œğ‘¡)] (7.7) En dâ€™autres termes, lâ€™influence de â„ğ‘¡â€²sera attÃ©nuÃ©e par un facteur ğ‘Šğ‘¡âˆ’ğ‘¡â€²âˆ’1 â„ tanhâ€²(ğ‘œğ‘¡â€²+1) â‹… â‹¯ â‹… tanhâ€²(ğ‘œğ‘¡). Rappelons maintenant Ã  quoi ressemblent la fonction tanh et sa dÃ©rivÃ©e : 42 Chapitre 7. RÃ©seaux neuronaux rÃ©currentsIntroduction au Deep Learning (notes de cours) On peut voir Ã  quel point les gradients se rapprochent rapidement de 0 pour des entrÃ©es plus grandes (en valeur absolue) que 2, et avoir plusieurs termes de ce type dans une dÃ©rivation en chaÃ®ne fera tendre les termes correspondants vers 0. En dâ€™autres termes, le gradient de lâ€™Ã©tat cachÃ© au temps ğ‘¡sera seulement influencÃ© par quelques uns de ses prÃ©dÃ©cesseurs {â„ğ‘¡âˆ’1 , â„ğ‘¡âˆ’2 , â€¦ }et les les dÃ©pendances Ã  long terme seront ignorÃ©es lors de lâ€™actualisation des paramÃ¨tres du modÃ¨le par descente de gradient. Il sâ€™agit dâ€™une occurrence dâ€™un phÃ©nomÃ¨ne plus gÃ©nÃ©ral connu sous le nom de vanishing gradient . 7.2Long Short Term Memory Les blocs Long Short Term Memory (LSTM, [ Hochreiter and Schmidhuber, 1997 ]) ont Ã©tÃ© conÃ§us comme une alternative Ã  aux blocs rÃ©currents classiques. Ils visent Ã  attÃ©nuer lâ€™effet de vanishing gradient par lâ€™utilisation de portes qui codent explicitement quelle partie de lâ€™information doit (resp. ne doit pas) Ãªtre utilisÃ©e. Les portes dans les rÃ©seaux neuronaux Dans la terminologie des rÃ©seaux de neurones, une porte ğ‘” âˆˆ [0, 1]ğ‘‘est un vecteur utilisÃ© pour filtrer les informations dâ€™un vecteur caractÃ©ristique entrant ğ‘£ âˆˆ â„ğ‘‘de telle sorte que le rÃ©sultat de lâ€™application de la porte est : ğ‘” âŠ™ ğ‘£. oÃ¹ âŠ™est le produit Ã©lÃ©ment-par-Ã©lÃ©ment. La porte ğ‘”aura donc tendance Ã  supprimer une partie des caractÃ©ristiques de ğ‘£. (celles qui correspondent Ã  des valeurs trÃ¨s faibles de ğ‘”). Dans ces blocs, un Ã©tat supplÃ©mentaire est utilisÃ©, appelÃ© Ã©tat de la cellule ğ¶ğ‘¡. Cet Ã©tat est calculÃ© comme suit : ğ¶ğ‘¡= ğ‘“ğ‘¡âŠ™ ğ¶ğ‘¡âˆ’1 + ğ‘–ğ‘¡âŠ™ Ìƒğ¶ğ‘¡ (7.8) oÃ¹ ğ‘“ğ‘¡est appelÃ©e forget gate (elle pousse le rÃ©seau Ã  oublier les parties inutiles de lâ€™Ã©tat passÃ© de la cellule), ğ‘–ğ‘¡est lâ€input gateet Ìƒğ¶ğ‘¡est une version actualisÃ©e de lâ€™Ã©tat de la cellule (qui, Ã  son tour, peut Ãªtre partiellement censurÃ©e par lâ€ input gate). 7.2.Long Short Term Memory 43Introduction au Deep Learning (notes de cours) Laissons de cÃ´tÃ© pour lâ€™instant les dÃ©tails concernant le calcul de ces 3 termes et concentrons-nous plutÃ´t sur la faÃ§on dont la formule ci-dessus est est significativement diffÃ©rente de la rÃ¨gle de mise Ã  jour de lâ€™Ã©tat cachÃ© dans le modÃ¨le classique. En effet, dans ce cas, si le rÃ©seau lâ€™apprend (par lâ€™intermÃ©diaire de ğ‘“ğ‘¡), lâ€™information complÃ¨te de lâ€™Ã©tat prÃ©cÃ©dent de la cellule ğ¶ğ‘¡âˆ’1peut Ãªtre rÃ©cupÃ©rÃ©e, ce qui permet aux gradients de se propager Ã  rebours de lâ€™axe du temps (et de ne plus disparaÃ®tre). Alors, le lien entre lâ€™Ã©tat de la cellule et lâ€™Ã©tat cachÃ© est : â„ğ‘¡= ğ‘œğ‘¡âŠ™tanh (ğ¶ğ‘¡) . (7.9) En dâ€™autres termes, lâ€™Ã©tat cachÃ© est la version transformÃ©e (par la fonction tanh) de lâ€™Ã©tat de la cellule, encore censurÃ© par une porte de sortie ( output gate )ğ‘œğ‘¡. Toutes les portes utilisÃ©es dans les formules ci-dessus sont dÃ©finies de maniÃ¨re similaire : ğ‘“ğ‘¡ = ğœ(ğ‘Šğ‘“â‹… [â„ğ‘¡âˆ’1 , ğ‘¥ğ‘¡] + ğ‘ğ‘“) (7.10) ğ‘–ğ‘¡ = ğœ(ğ‘Šğ‘–â‹… [â„ğ‘¡âˆ’1 , ğ‘¥ğ‘¡] + ğ‘ğ‘–) (7.11) ğ‘œğ‘¡ = ğœ(ğ‘Šğ‘œâ‹… [â„ğ‘¡âˆ’1 , ğ‘¥ğ‘¡] + ğ‘ğ‘œ) (7.12) oÃ¹ ğœest la fonction dâ€™activation sigmoÃ¯de (dont les valeurs sont comprises dans [0, 1]) et [â„ğ‘¡âˆ’1 , ğ‘¥ğ‘¡]la concatÃ©nation des caractÃ©ristiques â„ğ‘¡âˆ’1etğ‘¥ğ‘¡. Enfin, lâ€™Ã©tat de cellule mis Ã  jour Ìƒğ¶ğ‘¡est calculÃ© comme suit : Ìƒğ¶ğ‘¡=tanh (ğ‘Šğ¶â‹… [â„ğ‘¡âˆ’1 , ğ‘¥ğ‘¡] + ğ‘ğ¶) . (7.13) Il existe dans la littÃ©rature de nombreuses variantes de ces blocs LSTM qui reposent toujours sur les mÃªmes principes de base. 7.3Gated Recurrent Unit Une paramÃ©trisation lÃ©gÃ¨rement diffÃ©rente dâ€™un bloc rÃ©current est utilisÃ©e dans les Gated Recurrent Units (GRU, [ Choet al., 2014 ]). Les GRUs reposent Ã©galement sur lâ€™utilisation de portes pour laisser (de maniÃ¨re adaptative) lâ€™information circuler Ã  travers le temps. Une premiÃ¨re diffÃ©rence significative entre les GRUs et les LSTMs est que les GRUs nâ€™ont pas recours Ã  lâ€™utilisation dâ€™un Ã©tat de cellule. Au lieu de cela, la rÃ¨gle de mise Ã  jour de lâ€™Ã©tat cachÃ© est la suivante : â„ğ‘¡= (1 âˆ’ ğ‘§ğ‘¡) âŠ™ â„ğ‘¡âˆ’1 + ğ‘§ğ‘¡âŠ™ Ìƒâ„ğ‘¡ (7.14) oÃ¹ ğ‘§ğ‘¡est une porte qui Ã©quilibre (par caractÃ©ristique) la quantitÃ© dâ€™informations qui est conservÃ©e de lâ€™Ã©tat cachÃ© prÃ©cÃ©dent avec la quantitÃ© dâ€™informations qui doit Ãªtre mise Ã  jour en utilisant le nouvel Ã©tat cachÃ© candidat Ìƒâ„ğ‘¡, calculÃ© comme suit : Ìƒâ„ğ‘¡=tanh (ğ‘Š â‹… [ğ‘Ÿğ‘¡âŠ™ â„ğ‘¡âˆ’1 , ğ‘¥ğ‘¡] + ğ‘) , (7.15) oÃ¹ ğ‘Ÿğ‘¡est une porte supplÃ©mentaire qui peut cacher une partie de lâ€™Ã©tat cachÃ© prÃ©cÃ©dent. Les formules pour les portes ğ‘§ğ‘¡etğ‘Ÿğ‘¡sont similaires Ã  celles fournies pour ğ‘“ğ‘¡,ğ‘–ğ‘¡etğ‘œğ‘¡dans le cas des LSTMs. Une Ã©tude graphique de la capacitÃ© de ces variantes de rÃ©seaux rÃ©currents Ã  apprendre des dÃ©pendances Ã  long terme est fournie dans [ Madsen, 2019 ]. 44 Chapitre 7. RÃ©seaux neuronaux rÃ©currentsIntroduction au Deep Learning (notes de cours) 7.4Conclusion Dans ce chapitre et le prÃ©cÃ©dent, nous avons passÃ© en revue les architectures de rÃ©seaux de neurones qui sont utilisÃ©es pour apprendre Ã  partir de donnÃ©es temporelles ou sÃ©quentielles. En raison de contraintes de temps, nous nâ€™avons pas abordÃ© les modÃ¨les basÃ©s sur lâ€™attention dans ce cours. Nous avons prÃ©sentÃ© les modÃ¨les convolutifs qui visent Ã  extraire des formes locales discriminantes dans les sÃ©ries et les modÃ¨les rÃ©currents qui exploitent plutÃ´t la notion de sÃ©quence. Concernant ces derniers, des variantes visant Ã  faire face Ã  lâ€™effet de gradient Ã©vanescent ont Ã©tÃ© introduites. Il est Ã  noter que les modÃ¨les rÃ©currents sont connus pour nÃ©cessiter plus de donnÃ©es dâ€™entraÃ®nement que leurs homologues convolutifs. 7.4. Conclusion 45Introduction au Deep Learning (notes de cours) 46 Chapitre 7. RÃ©seaux neuronaux rÃ©currentsBIBLIOGRAPHIE [Goh17] Gabriel Goh. Why momentum really works. Distill , 2017. URL: http://distill.pub/2017/momentum . [KB15] Diederik P. Kingma and Jimmy Ba. Adam: a method for stochastic optimization. In Yoshua Bengio and Yann LeCun, editors, ICLR. 2015. [SHK+14] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dro- pout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research , 15(56) :1929â€“1958, 2014. URL: http://jmlr.org/papers/v15/srivastava14a.html . [FFW+19] Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, and Pierre-Alain Muller. Deep learning for time series classification: a review. Data Mining and Knowledge Discovery , 33(4) :917â€“ 963, 2019. [FLF+20] Hassan Ismail Fawaz, Benjamin Lucas, Germain Forestier, Charlotte Pelletier, Daniel F Schmidt, Jonathan Weber, Geoffrey I Webb, Lhassane Idoumghar, Pierre-Alain Muller, and FranÃ§ois Petitjean. Inceptiontime: finding alexnet for time series classification. Data Mining and Knowledge Discovery , 34(6) :1936â€“1962, 2020. [LGMT16] Arthur Le Guennec, Simon Malinowski, and Romain Tavenard. Data Augmentation for Time Series Clas- sification using Convolutional Neural Networks. In ECML/PKDD Workshop on Advanced Analytics and Learning on Temporal Data . Riva Del Garda, Italy, September 2016. [LBBH98] Yann LeCun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to docu- ment recognition. Proceedings of the IEEE , 86(11) :2278â€“2324, 1998. [CVMerrienboerBB14] Kyunghyun Cho, Bart Van MerriÃ«nboer, Dzmitry Bahdanau, and Yoshua Bengio. On the pro- perties of neural machine translation: encoder-decoder approaches. 2014. arXiv:1409.1259 . [HS97] Sepp Hochreiter and JÃ¼rgen Schmidhuber. Long short-term memory. Neural computation , 9(8) :1735â€“1780, 1997. [Mad19] Andreas Madsen. Visualizing memorization in rnns. Distill , 2019. URL: https://distill.pub/2019/ memorization-in-rnns . 47",
    "metadata": {
      "source_doc_id": "doc_1_3e92e9de",
      "source_doc_name": "cours deep learning.pdf",
      "source_type": "fichier: application/pdf",
      "char_length": 62790,
      "word_count": 10249,
      "lang": "fr",
      "created_at": "2025-07-08T17:26:37.143631"
    }
  }
]